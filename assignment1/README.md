# Assignment 1

Implement and test various SiLU implementations.

### PyTorch

```bash
$ uv run python assignment1/silu/silu_torch.py
================================================================================
PyTorch SiLU implementation and performance profiling
================================================================================
[+] CUDA device: Quadro RTX 6000
[+] Tensor shape: torch.Size([8192, 8192])
[+] Running 100 warmup iterations...
[+] Exporting trace to torch_silu.json

================================================================================
Performance Numbers
================================================================================
[+] Time for SiLU: 4.438591957092285 ms
[+] Bandwidth: 120.95523021487728 GBps

================================================================================
Correctness Test
================================================================================
[+] Test closeness: PASS (<0.00e+00)

$
```

### Triton

```bash
$ uv run python assignment1/silu/silu_triton_test.py

CUDA device: Quadro RTX 6000

================================================================================
Correctness Test
================================================================================
Tensor Shape         Test Status          Max Diff
--------------------------------------------------------------------------------
(1024, 1024)         PASS                 4.77e-07
(2048, 2048)         PASS                 7.15e-07
(4096, 4096)         PASS                 9.54e-07
(8192, 8192)         PASS                 9.54e-07

================================================================================
Runtime Benchmark
================================================================================
Size                 PyTorch (ms)    Triton (ms)     Speedup
--------------------------------------------------------------------------------
(1024, 1024)         0.0576          0.0485          1.19
(2048, 2048)         0.2772          0.0917          3.02
(4096, 4096)         1.0691          0.2691          3.97
(8192, 8192)         4.3127          0.9996          4.31

================================================================================
Bandwidth Benchmark
================================================================================
Size                 PyTorch (GB/s)  Triton (GB/s)   Speedup
--------------------------------------------------------------------------------
(1024, 1024)         145.76          173.09          1.19
(2048, 2048)         121.07          366.06          3.02
(4096, 4096)         125.55          498.79          3.97
(8192, 8192)         124.48          537.06          4.31

$
```

### CUDA

```bash
$ make
$ ./silu
================================================================================
SiLU Kernel Tests
================================================================================
CUDA device:    Quadro RTX 6000
CPU time:       321.3388 ms
GPU time:       0.9674 ms
Speedup:        332.16x
Bandwidth:      554.95 GB/s
Max error:      1.91e-06
Status:         PASSED

$
```
